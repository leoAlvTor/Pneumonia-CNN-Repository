{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia Classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural networks (CNN) can be used as an efficient tool for detecting diseases between different types of medical imaging in a fast a reliable way, thus, this paper illustrate the creation and training of a CNN from scratch, describing the importance of data preprocessing as an effective approach for producing better results, since raw data give bad results and also takes more time to train a standard neural network(NN). This paper is based on another research article, but the difference is the way data management, as data augmentation is not the correct procedure for reducing the effort at the moment of developing a solution for this science area. As the main result, the solution mentioned can help radiology and medical personnel to categorize, in this case, if a patient has or not the pneumonia disease, taking into account the difficulty and the delay of reading an X-Ray image. About the dataset, its name is Chest X-Ray Image Dataset, itâ€™s a public dataset of Kaggle and contains 5856 Jpeg images organized in three directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Library import process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Linear algebra modules.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Module for working with OS (Linux).\n",
    "import os\n",
    "\n",
    "# Import keras classes for CNN design.\n",
    "from keras.utils import Sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "# Open CV module for computer vision.\n",
    "import cv2\n",
    "\n",
    "# Keras module for loading our pretrained model.\n",
    "from keras.models import model_from_json\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to read Images from both directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    @param dirnameNormal\n",
    "    Directory for normal X-Ray images.\n",
    "    \n",
    "    @param dirnamePneumonia\n",
    "    Directory for Pneumonia X-Ray images.\n",
    "    \n",
    "    Return two arrays, both contains image directories.\n",
    "    \n",
    "\"\"\"\n",
    "def readDirectory(dirnameNormal, dirnamePneumonia):\n",
    "    array1 = []\n",
    "    array2 = []\n",
    "    for i in os.listdir(dirnameNormal):\n",
    "        if '.DS_Store' not in i:\n",
    "            array1.append(dirnameNormal + '/' + str(i))\n",
    "            array2.append(0)\n",
    "        \n",
    "    for i in os.listdir(dirnamePneumonia):\n",
    "        if '.DS_Store' not in i:\n",
    "            array1.append(dirnamePneumonia + '/' + str(i))\n",
    "            array2.append(1)\n",
    "        \n",
    "    return array1, array2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories are loaded into arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Dataset root directory.\n",
    "base_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/'\n",
    "\n",
    "# Arrays Train X and Y are loaded with directories.\n",
    "train_x, train_y = readDirectory(base_dir+'train/NORMAL', base_dir+'train/PNEUMONIA')\n",
    "print('Reading on train directory finished!')\n",
    "\n",
    "# Arrays Test X and Y are loaded with directories.\n",
    "test_x, test_y = readDirectory(base_dir+'test/NORMAL', base_dir+'test/PNEUMONIA')\n",
    "print('Reading on test directory finished!')\n",
    "\n",
    "# Validation directories loaded in variables.\n",
    "val_x, val_y = readDirectory(base_dir+'val/NORMAL', base_dir+'val/PNEUMONIA')\n",
    "print('Reading on val directory finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join train and test arrays into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length verification before joining process!')\n",
    "print(len(train_x), '<-->', len(train_y))\n",
    "print(len(test_x), '<-->', len(test_y))\n",
    "print(len(val_x), '<-->', len(val_y))\n",
    "\n",
    "# Joining train and test lists into one.\n",
    "\n",
    "files = train_x + test_x\n",
    "\n",
    "# Joining train and test labels.\n",
    "\n",
    "labels = train_y + test_y\n",
    "\n",
    "print('Length verificacion after joining process!')\n",
    "print(len(files), '<-->', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "files_shuffled, labels_shuffled = shuffle(files, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_filenames, X_val_filenames, y_train, y_val = train_test_split(files_shuffled, labels_shuffled, test_size=0.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Generator and Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# This class inherit Sequence class in order to create a custom generator\n",
    "class Data_Generator(Sequence):\n",
    "    \n",
    "    # We feed oun gerator with our parameters.\n",
    "    def __init__(self, image_filenames, labels, batch_size):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    # Computes the number of batches to produce.\n",
    "    def __len__(self) :\n",
    "        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(np.int)\n",
    "    \n",
    "    # We preprocess our dataset with the current batch (Here is where magic happens).\n",
    "    def __getitem__(self, idx) :\n",
    "        batch_x = self.image_filenames[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size : (idx+1) * self.batch_size]\n",
    "        \n",
    "        return np.array(\n",
    "            [self.preprocess_image(directory) for directory in batch_x]\n",
    "        ), np.array(batch_y)\n",
    "        \n",
    "    \n",
    "    # Preprocess a single image and return an array.\n",
    "    def preprocess_image(self, directory):\n",
    "        # Read image from directory\n",
    "        img = cv2.imread(directory, cv2.IMREAD_GRAYSCALE)\n",
    "        # Resize the image\n",
    "        img = cv2.resize(src= img, dsize= (300, 300), interpolation = cv2.INTER_AREA)\n",
    "        # Denoise the image\n",
    "        img = cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
    "        # Normalize the image\n",
    "        img = img/255\n",
    "        \n",
    "        img.shape += (1,)\n",
    "        \n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess a single image and return an array.\n",
    "def preprocess_image(directory):\n",
    "    # Read image from directory\n",
    "    img = cv2.imread(directory, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize the image\n",
    "    img = cv2.resize(src= img, dsize= (300, 300), interpolation = cv2.INTER_AREA)\n",
    "    # Denoise the image\n",
    "    img = cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
    "    # Normalize the image\n",
    "    img = img/255\n",
    "        \n",
    "    img.shape += (1,)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation of the custom Data Generator with 64 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "my_training_batch_generator = Data_Generator(X_train_filenames, y_train, batch_size)\n",
    "my_validation_batch_generator = Data_Generator(X_val_filenames, y_val, batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential class instantiation for the CNN model.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with a shape of 300x300 per 1 channel.\n",
    "model.add(Conv2D(16, (3, 3), activation=\"relu\", input_shape=(300, 300, 1)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=\"tanh\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=\"tanh\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"tanh\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(activation = 'relu', units = 128))\n",
    "model.add(Dense(activation = 'sigmoid', units = 1))\n",
    "\n",
    "# Compile the CNN model, with adam optimizer.\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Print our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "    generator=my_training_batch_generator,\n",
    "    steps_per_epoch = int( np.ceil(len(X_train_filenames) / batch_size)),\n",
    "    epochs= 5,\n",
    "    verbose= 1,\n",
    "    validation_data= my_validation_batch_generator,\n",
    "    validation_steps= int( np.ceil(len(X_val_filenames) / batch_size)),\n",
    "    use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train accuracy vs Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_training = history.history['accuracy']\n",
    "accuracy_testing = history.history['val_accuracy']\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_training = np.array(accuracy_training)\n",
    "acc_testing = np.array(accuracy_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the accuracies in a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_accuracies = pd.DataFrame(list(zip(acc_training, acc_testing)), columns=['ACC_Training', 'ACC_Testing'])\n",
    "dataframe_accuracies.to_csv('dataframe_accuracies.csv')\n",
    "dataframe_accuracies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the accuracies obtained by the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "plt.grid()\n",
    "plt.plot(accuracy_training, color='b', label=\"Training accuracy\")\n",
    "plt.xticks(np.arange(1, epochs, 1))\n",
    "plt.xlabel('EPOCHS')\n",
    "plt.ylabel('Accuracy en Training')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "plt.grid()\n",
    "plt.plot(accuracy_testing, color='r')\n",
    "plt.xticks(np.arange(1, epochs, 1))\n",
    "plt.xlabel('EPOCHS')\n",
    "plt.ylabel('Accuracy en Validation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Podemos constatar que el modelo propuesto en el presente artÃ­culo supera en ambas medidas de calidad al modelo base con una considerable diferencia, adicionalmente se obtiene esos valores de train y test con un nÃºmero mucho menor de ephocs en comparaciÃ³n al modelo base.\n",
    "\n",
    "Para la realizaciÃ³n de este artÃ­culo tomamos el modelo de un paper debidamente publicado, asÃ­ que el desarrollo del modelo propuesto, las pruebas y errores, fueron un gran reto para los autores porque competÃ­amos con profesionales con mÃ¡s experiencia en el campo de la ciencia de datos. Como trabajo futuro pretendemos, extender este trabajo en la clasificaciÃ³n de imÃ¡genes de rayos X, proyectÃ¡ndonos a mejorar la precisiÃ³n en clasificar imÃ¡genes que contienen cÃ¡ncer o tumores, aportando a la medicina y mÃ¡s que todo a salvar vidas.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
