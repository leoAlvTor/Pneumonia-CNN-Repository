{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM for Pneumonia Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The present notebook is used only for comparative purposes, representing how feasible is a CNN over a SVM for classificating larga datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test lists load process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "directorios_train = []\n",
    "directorios_test = []\n",
    "\n",
    "for i in os.listdir('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train/NORMAL/'):\n",
    "    if \"DS_Store\" not in i:\n",
    "        directorios_train.append('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train/NORMAL/'+i)\n",
    "    \n",
    "for i in os.listdir('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train/PNEUMONIA/'):\n",
    "    if \"DS_Store\" not in i:\n",
    "        directorios_train.append('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/train/PNEUMONIA/'+i)\n",
    "\n",
    "\n",
    "for i in os.listdir('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test/NORMAL/'):\n",
    "    if \"DS_Store\" not in i:\n",
    "        directorios_test.append('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test/NORMAL/'+i)\n",
    "\n",
    "        \n",
    "for i in os.listdir('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test/PNEUMONIA/'):\n",
    "    if \"DS_Store\" not in i:\n",
    "        directorios_test.append('/kaggle/input/chest-xray-pneumonia/chest_xray/chest_xray/test/PNEUMONIA/'+i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test images preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_train = []\n",
    "etiquetas_train = []\n",
    "\n",
    "imagenes_test = []\n",
    "etiquetas_test = []\n",
    "\n",
    "# For each image in train directory the image is preprocesed and saved into a new array along its label.\n",
    "for i in directorios_train:\n",
    "    img = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (300, 300))\n",
    "    imagenes_train.append(img)\n",
    "    if (\"NORMAL\" in i) or (\"IM-\" in i) :\n",
    "        etiquetas_train.append(0)\n",
    "    elif \"person\" in i:\n",
    "        etiquetas_train.append(1)\n",
    "        \n",
    "\n",
    "# For each image in test directory the image is preprocesed and saved into a new array along its label.\n",
    "for i in directorios_test:\n",
    "    img = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (300, 300))\n",
    "    imagenes_test.append(img)\n",
    "    if (\"NORMAL\" in i) or (\"IM-\" in i) :\n",
    "        etiquetas_test.append(0)\n",
    "    elif \"person\" in i:\n",
    "        etiquetas_test.append(1)\n",
    "\n",
    "print('Finaliza el segundo proceso!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling Train\n",
    "imagenes_train_shuffle, etiquetas_train_shuffle = shuffle(imagenes_train, etiquetas_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling Test\n",
    "imagenes_test_shuffle, etiquetas_test_shuffle = shuffle(imagenes_test, etiquetas_test, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape of the original train list to only one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "leo = np.array(imagenes_train_shuffle)\n",
    "nsamples, nx, ny = leo.shape\n",
    "d2_train_dataset = leo.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA application for reducing dimension to get a better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_train_dataset_PCA = PCA(n_components=1)\n",
    "d2_train_dataset_PCA = d2_train_dataset_PCA.fit_transform(d2_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape of the original test list to one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenes_test_array = np.array(imagenes_test_shuffle)\n",
    "nsamples, nx, ny = imagenes_test_array.shape\n",
    "d2_test_dataset = imagenes_test_array.reshape((nsamples, nx*ny))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA application for reducing dimension to get a better performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2_test_dataset_PCA = PCA(n_components=1)\n",
    "d2_test_dataset_PCA = d2_test_dataset_PCA.fit_transform(d2_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM application for image classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_svm = svm.SVC()\n",
    "classification_svm.fit(d2_train_dataset_PCA, etiquetas_train)\n",
    "\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "svmKernelAccuracyDict = dict()\n",
    "\n",
    "# Testing the same data with three different kernels\n",
    "for kernel in kernels:\n",
    "    svc = svm.SVC(kernel= kernel, C=10, gamma=100).fit(d2_train_dataset_PCA, etiquetas_train)\n",
    "    accuracy = accuracy_score(etiquetas_test, y_pred)\n",
    "    svmKernelAccuracyDict[kernel] = accuracy\n",
    "print('Proceso Terminado!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svmKernelAccuracyDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "Finalmente la SVM no pudo mejorar en precisión a la red neuronal, esto es debido a que las SVM no hacen uso de las capas max pooling y seguramente el proceso de entrenamiento cae directamente en un sobre entrenamiento de modo que el algoritmo no toma en cuenta a la información más representativa.\n",
    "\n",
    "Como una de las varias causas por la que una svm no supera a las cnn Tabla 4 es porque no hacen uso de la gpu del computador y solamente hacen uso del cpu, en informática se conoce que tanto el cpu como la gpu están orientadas a distintos tipos de tareas, siendo una gpu óptima para realizar operaciones con vectores con varias dimensiones o más conocidos como tensores, al momento que una svm está en el proceso de entrenamiento implica que está haciendo operaciones con tensores haciendo uso del cpu, como consecuencia se observa que la svm tarda mucho más tiempo en terminar con el entrenamiento además de constatar que la maquina informa que el cpu esta sobrecargado, a esto podemos adicionar que las svm no son óptimas con conjuntos de datos extensos ni tampoco con arrays de más de dos dimensiones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
